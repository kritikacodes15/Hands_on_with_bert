{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b21dd947-ab51-4c85-a84d-8c6676d5f589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "     ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.1/12.0 MB 787.7 kB/s eta 0:00:16\n",
      "     - -------------------------------------- 0.4/12.0 MB 2.7 MB/s eta 0:00:05\n",
      "     -- ------------------------------------- 0.8/12.0 MB 4.6 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.4/12.0 MB 5.8 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 1.9/12.0 MB 7.0 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 2.3/12.0 MB 7.2 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 2.9/12.0 MB 7.7 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 3.5/12.0 MB 8.5 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 3.9/12.0 MB 8.5 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 4.0/12.0 MB 7.8 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 4.6/12.0 MB 8.3 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 5.0/12.0 MB 8.2 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 5.5/12.0 MB 8.6 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 5.8/12.0 MB 8.3 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 6.3/12.0 MB 8.4 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 6.8/12.0 MB 8.5 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.2/12.0 MB 8.5 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 7.7/12.0 MB 8.6 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.2/12.0 MB 8.9 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 8.7/12.0 MB 8.9 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.1/12.0 MB 8.9 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 9.6/12.0 MB 9.0 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 9.9/12.0 MB 8.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 10.3/12.0 MB 9.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 10.8/12.0 MB 9.8 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.1/12.0 MB 9.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 11.5/12.0 MB 9.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.0/12.0 MB 9.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.0/12.0 MB 9.1 MB/s eta 0:00:00\n",
      "Collecting safetensors>=0.4.3\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "     ---------------------------------------- 0.0/320.2 kB ? eta -:--:--\n",
      "     ------------------------------------- 320.2/320.2 kB 20.7 MB/s eta 0:00:00\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "     ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "     ------- -------------------------------- 0.5/2.7 MB 15.9 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 1.0/2.7 MB 13.3 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 1.4/2.7 MB 13.1 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 1.8/2.7 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 2.1/2.7 MB 9.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 2.5/2.7 MB 9.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.7/2.7 MB 9.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\vikram yadav\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vikram yadav\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vikram yadav\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vikram yadav\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0\n",
      "  Downloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "     ---------------------------------------- 0.0/564.3 kB ? eta -:--:--\n",
      "     --------------------------- --------- 419.8/564.3 kB 12.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- 564.3/564.3 kB 11.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\vikram yadav\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\vikram yadav\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vikram yadav\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.2.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vikram yadav\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vikram yadav\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\vikram yadav\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vikram yadav\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vikram yadav\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vikram yadav\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vikram yadav\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.35.3 safetensors-0.6.2 tokenizers-0.22.1 transformers-4.57.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\Vikram Yadav\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4b31f7c-d782-4245-a200-b7921f6185d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer , BertModel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d6e3338-617e-42aa-a863-45de25f9def2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa8ecab9-6b92-4c24-92a4-c2d2c391ef8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cecdce9a577a4ab7bd34670ffc3c6b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vikram Yadav\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Vikram Yadav\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3ca332aaa4452da5e978fa738d1221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd2f33c8b854fdeb8067b2b92cad963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832e1a0a631e4c3994401d9730970300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b55272-564c-4ba3-91c1-968c5b4817bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1045, 2293, 6207,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer('I love apple',return_tensors='pt')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84c595e0-977c-4a84-9748-289b5a45bb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  2293,  6207,   102,     0,     0,     0,     0,     0],\n",
       "        [  101,  1045,  2066,  2725,  7976,  4454,  1998, 17662,  2227,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(['I love apple','I like doing Artificial Intelligence and Hugging Face'],padding = True,return_tensors='pt')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2ee967a-9c05-4da3-b315-1641fbb41953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa292321792849aaa948cad2157814e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vikram Yadav\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Vikram Yadav\\.cache\\huggingface\\hub\\models--bert-large-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167b7acf21c74b1889196e0565afabaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BertModel.from_pretrained(\"bert-large-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caa716eb-b746-486f-9aed-0d795102f73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24e9606b-4d19-4373-9a18-ccd24dde65f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'i',\n",
       " 'love',\n",
       " 'apple',\n",
       " '[SEP]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(tokens['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae5fbce2-3630-4bf3-82b0-06ffc455778c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.0922e-01, -6.9534e-01, -4.7913e-01,  ..., -2.6343e-01,\n",
       "          -6.7809e-01,  9.4170e-02],\n",
       "         [-5.0443e-01, -3.2651e-01, -3.6556e-01,  ..., -2.7409e-01,\n",
       "           7.1644e-02,  7.1939e-04],\n",
       "         [-6.4037e-01, -1.8058e-01, -3.6765e-01,  ..., -7.0411e-02,\n",
       "          -2.9158e-01,  1.8175e-01],\n",
       "         ...,\n",
       "         [-8.3508e-02, -4.1476e-01, -1.7199e-01,  ..., -3.8361e-01,\n",
       "          -6.5108e-01,  1.1551e-01],\n",
       "         [ 1.3675e-01,  1.7072e-01, -6.5266e-02,  ..., -1.1469e-01,\n",
       "          -3.7196e-01, -1.4328e-01],\n",
       "         [ 5.2278e-02, -3.8317e-01, -8.0828e-02,  ...,  1.7023e-01,\n",
       "          -7.3571e-01,  3.8457e-02]],\n",
       "\n",
       "        [[-2.2776e-01, -2.3784e-01, -8.2353e-01,  ..., -6.4831e-01,\n",
       "          -3.2784e-01, -1.4374e-02],\n",
       "         [-1.7751e-01, -4.4814e-01, -3.6679e-01,  ...,  1.5008e-01,\n",
       "           1.4789e-01, -2.7467e-03],\n",
       "         [-8.2493e-01,  3.7518e-02, -1.7054e-01,  ...,  2.6480e-01,\n",
       "           9.8705e-02, -3.3581e-01],\n",
       "         ...,\n",
       "         [-6.4348e-01, -9.2747e-02,  5.4013e-01,  ..., -5.2743e-01,\n",
       "          -7.0279e-02, -3.8433e-01],\n",
       "         [-5.9309e-02, -8.7494e-02, -1.5636e-01,  ...,  1.4847e-01,\n",
       "          -2.3744e-01, -1.6484e-01],\n",
       "         [-2.7958e-01,  1.4050e-01, -3.6599e-01,  ..., -4.1385e-02,\n",
       "          -8.4492e-01, -3.4728e-01]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['last_hidden_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d89c5af0-a790-4c52-abaf-6e42a764d755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 1024])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feb64e9-8861-4e86-a005-a4c36cab2921",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['pooler_output'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (System)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
